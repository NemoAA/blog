## 1. ClickHouse写入抖动分析

### 环境信息

```
Red Hat Enterprise Linux Server release 7.4
ClickHouse-18.14.15
```

### 问题

```
插入在同一服务器上执行有时候快几百ms,有时候慢7-8秒
```

### 根本原因

```
磁盘IO能力不足及内存紧张导致
```

### 诊断步骤

#### 1. 现象

通过分析`top`命令的输出,发现如下两个问题

* 系统iowait升高(观察发现高峰期可达到30%),导致系统平均负载增大,磁盘可能存在瓶颈
* 系统使用了swap,可能存在内存瓶颈

![](https://raw.githubusercontent.com/NemoAA/blog/master/pic/case-analyze-pic/ch-top.png)                                                                                               

接下来我们从磁盘IO和内存两个方面分析系统状态

#### 2. iowait分析

iowait升高,我们来查询系统I/O情况,我们使用`iostat`和`dstat`这两个工具来分析

##### 2.1 dstat

使用`dstat`来查看CPU和I/O的试用情况

![](https://raw.githubusercontent.com/NemoAA/blog/master/pic/case-analyze-pic/ch-dstat.png)

从`dstat`输出可以看出在iowait升高时,磁盘读(read)都会很大,说明iowait的升高和读请求有关,同时通过`pidstat -d 1`可以看出是clickhouse进程导致

##### 2.2 iostat

![](https://raw.githubusercontent.com/NemoAA/blog/master/pic/case-analyze-pic/ch-iostat.png)

同时从`iostat`命令输出也可以看出在,磁盘读非常大导致一直处于100%繁忙状态,同时从clickhouse系统视图中也可以看出,此时正在进行查询

![](https://raw.githubusercontent.com/NemoAA/blog/master/pic/case-analyze-pic/ch-query.png)

```
-- 查看clickhouse正在运行查询命令
watch -n2 "clickhouse-client --query='select address,port,elapsed,query,written_bytes,written_rows,read_bytes,read_rows,memory_usage from system.processes;'"
```

##### 2.3 结论

从上面分析可以看出,磁盘io存在瓶颈,且主要在读操作上

#### 3. 内存分析

下面先看一张内存关系图

![](https://raw.githubusercontent.com/NemoAA/blog/master/pic/case-analyze-pic/memory-info.png)

##### 3.1 sar

通过`sar -r -S 1 10` 命令输出可以看出,系统剩余内存和cache在一个范围内小幅波动,且cache非常大,cache可以使用bcc工具中的cachetop或者cachestat来查看缓存命中率(因为没有root权限,暂时无法查看)

![](https://raw.githubusercontent.com/NemoAA/blog/master/pic/case-analyze-pic/ch-sar.png)

通过/proc/zoneinfo来查看剩余内存,内存阈值,匿名页及文件页的活跃情况

![1547086758277](https://raw.githubusercontent.com/NemoAA/blog/master/pic/case-analyze-pic/ch-swapzone.png)

从上图可以看出剩余内存(pages free)在一个范围内不停的波动,当他低于页低阈值(min)值时,又会增大到高于页高阈值(high),同时结合sar观察结果可以推出,剩余内存和缓层的变化是由于内存紧张产生内存回收和缓存再次分配的结果

使用下面脚本对按 VmSwap 使用量对进程排序,输出进程名称,进程ID以及SWAP用量

```
[clickhouse@tk107-ww-b05-dx1-14 ~]$ for file in /proc/*/status ; do awk '/VmSwap|Name|^Pid/{printf $2 " " $3}END{ print ""}' $file; done | sort -k 3 -n -r | head
clickhouse-serv 20495 168728 kB
python 30486 13316 kB
tuned 1677 10484 kB
polkitd 1147 9708 kB
python 30494 9324 kB
systemd 1 3060 kB
abrtd 1155 1848 kB
systemd-udevd 808 1608 kB
abrt-watch-log 1157 1388 kB
rsyslogd 1140 1116 kB
```

##### 3.2 结论

从上面可以看出在进行大查询的时候,系统内存页非常紧张

#### 4. 建议

* 1. 增加磁盘能力
  2. 调低clickhouse单个查询使用的内存

## 2. 餐饮通知/支付系统主节点:10.2.202.76服务器内存溢出

### 环境信息

```
Red Hat Enterprise Linux (RHEL) 7.0
PostgreSQL 9.6
```

### 问题

```
餐饮通知/支付系统主节点:10.2.202.76服务器内存溢出
```

### 根本原因

```
1.作为集群的主节点，服务器的内存只有30G,内存配置低
2.桌面进程gnome-shell占用的内存过大
```

**内存使用情况：**

![](https://ws1.sinaimg.cn/large/006tNc79ly1fz2r0myoqvj30su04275c.jpg)

内存几乎被使用完。

**cpu使用情况：**

![](https://ws1.sinaimg.cn/large/006tNc79ly1fz2r3e318zj30xy0aq79k.jpg)

kswapd1 占用过高是因为物理内存不足，使用swap分区与内存换页操作交换数据，导致CPU占用过高。

###  诊断步骤

```
1.查看占有内存较多的进程
```

![](https://ws3.sinaimg.cn/large/006tNc79ly1fz2r7ea1wij310g0a8n2q.jpg)

从上图中可可以看出桌面gnome相关的进程占用了大量的内存。

```
2.经过咨询相关人员，确定gnome进程可以关闭，所以杀死占有内存较多的gnome进程
```

杀死gnome相关进程之后内存使用情况：

![](https://ws2.sinaimg.cn/large/006tNc79ly1fz2qtdsgmhj314o0eadms.jpg)

杀进程之后内存得到了释放，有大约9个G的内存空闲，内存溢出问题得到了解决。但是服务器的内存配置确实是偏低，之后条件允许的话，建议升级内存配置。

## 3. 候补队列测试环境下使用patronictl更改wal_level参数没效果

### 环境信息

```
Red Hat Enterprise Linux (RHEL) 7.5
PostgreSQL 10.1
```

### 问题

```
北京现场同事反应，在候补队列测试环境中测试使用patronictl命令更改wal_level=logical 没有效果
```

### 根本原因

```
因候补队列测试环境13,14,15,16下存在多个集群，更改的数据库和查看的数据库不同
```

### 处理步骤

#### 1. 找到正确的数据库

#### 2.使用patronictl命令更改wal_level=logical

```
source /home/postgres/patroni/patronictl.sh 
patronictl -c /home/postgres/patroni/postgresyd.yml edit-config batmant1 --set postgresql.parameters.wal_level=logical
patronictl -c /home/postgres/patroni/postgresyd.yml restart batmant1
```

#### 3. 查看wal_level是否更改

```
show wal_level;
```

## 4. pgbackrest-2.07功能测试32k数据库恢复启动失败

### 环境信息

```
Red Hat Enterprise Linux (RHEL) 7.4
PostgreSQL 11.1
pgbackrest-2.07
```

### 问题

```
32k数据库恢复启动失败

[postgres@localhost pgsql]$ pg_ctl start
waiting for server to start....LOG:  listening on IPv4 address "0.0.0.0", port 5432
LOG:  listening on IPv6 address "::", port 5432
LOG:  listening on Unix socket "/tmp/.s.PGSQL.5432"
LOG:  database system was interrupted; last known up at 2019-01-09 17:27:12 CST
LOG:  starting archive recovery
2019-01-09 17:28:04.747 P00   INFO: archive-get command begin 2.07: [000000010000000000000002, pg_wal/RECOVERYXLOG] --log-level-console=info --pg1-path=/opt/pgsql/data --repo1-path=/var/lib/pgbackrest --stanza=demo
ERROR: [029]: page size is 32768 but must be 8192
2019-01-09 17:28:04.747 P00   INFO: archive-get command end: aborted with exception [029]
LOG:  invalid checkpoint record
FATAL:  could not locate required checkpoint record
HINT:  If you are not restoring from a backup, try removing the file "/opt/pgsql/data/backup_label".
LOG:  startup process (PID 38446) exited with exit code 1
LOG:  aborting startup due to startup process failure
LOG:  database system is shut down
 stopped waiting
pg_ctl: could not start server
Examine the log output.
```

### 根本原因

```
bug,作者未做这方面测试
```

### 重现步骤

编译参数

```
./configure --prefix=/opt/pgsql --with-perl --with-python --with-openssl --with-pam --with-libxml --with-libxslt --enable-thread-safety --with-wal-blocksize=64 --with-blocksize=32
```

```
[postgres@localhost ~]$ pgbackrest --stanza=demo --type=full --log-level-console=info backup

[postgres@localhost ~]$ pg_ctl stop

[postgres@localhost ~]$ pgbackrest --stanza=demo --delta --log-level-console=info restore

[postgres@localhost ~]$ pg_ctl start
```

### 处理步骤

### 参考

问题提交，作者的回复

https://github.com/pgbackrest/pgbackrest/issues/649

## 5. patroni频繁switchover是出现 start faild状态

### 环境信息

```
Red Hat Enterprise Linux (RHEL) 7.5
PostgreSQL 10.4
patroni1.5.3
```

### 问题

```
patroni手动反复切换后导致用patronictl查看状态时出现 start faild 状态
```

### 根本原因

```
patroni在使用patronictl switchover命令时，有可能存在数据库在patroni切换后第一次检测之后完成
```

### 处理步骤

#### 1. 主动处理方式

使用patronictl进入维护模式，当进入维护模式时会触发patroni马上执行检测数据库的行为

```
patronictl -c [config.yml] pause [scopename]
```

然后再将再推出维护模式

```
patronictl -c [config.yml] resume [scopename]
```

#### 2. 被动处理方式

被动处理方式只需使用patronictl show-config命令查看其ttl时间，待到下一个ttl时间再次使用patronictl list命令查看即可。